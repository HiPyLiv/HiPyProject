{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a natural dichotomy between data files that are easy for a computer to read, and data files that are easy for a human to read. In this article, we'll look at three common kinds of data files you are likely to encounter, are fairly human-readable, as well as being very easily manipulated in Python.\n",
    "\n",
    "## CSV files\n",
    "\n",
    "CSV is a very simple file format. The initials stand for \"comma-separated values\", and is used to encode a table of data. All spreadsheets and most databases can be exported into CSV format, and spreadsheet software such as Excel can import CSV files, so this is a nice format to be familiar with. Line-breaks (that is, <code>\\n</code> or <code>\\r</code> characters) separate the rows, and commas separate the values in each row. Well, it's a bit more lenient than that; you can choose any character to separate the values, but comma is the one that stuck around in the name for some reason. So, this is a perfectly reasonable .csv file:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "item,price\n",
    "bread,1.50\n",
    "rice,3.00\n",
    "bananas,0.30\n",
    "applesauce,2.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but so is"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "item|price\n",
    "bread|1.50\n",
    "rice|3.00\n",
    "bananas|0.30\n",
    "applesauce|2.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we should have come to expect in Python, there is a standard library module for handling .csv files, called (wait for it) <code>csv</code>. The two main functions offered by this module are <code>reader()</code> and <code>writer()</code>, respectively used for reading and writing <code>csv</code> files. Let's look at reading, first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movie name', ' gross', 'IMDB rating', 'IMDB votes']\n",
      "['Captain America: Civil War', ' 1153304495', '7.9', '418614']\n",
      "['Rogue One', ' 1056057273', '7.9', '334132']\n",
      "['Finding Dory', ' 1028570889', '7.4', '161213']\n",
      "['Zootopia', ' 1023784195', '8.1', '302479']\n",
      "['The Jungle Book', ' 966550600', '7.5', '200798']\n",
      "['The Secret Life Of Pets', ' 875457937', '6.6', '124027']\n",
      "['Batman v Superman', ' 873260194', '6.7', '479880']\n",
      "['Deadpool', ' 783112979', '8.0', '637685']\n",
      "['Suicide Squad', ' 745600054', '6.2', '404862']\n",
      "['Sing', ' 632443719', '7.2', '66129']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('topmovies.csv', encoding='UTF-8') as f: # file contains highest grossing films of 2016\n",
    "    moviescsv = csv.reader(f, delimiter=',')\n",
    "\n",
    "    for line in moviescsv:\n",
    "        print(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, each line is turned into a list of strings (by default). In this use of <code>reader</code>, we specified a delimiter character -- the character that separates each entry. We chose a comma, although this is redundant since it is the default anyway.\n",
    "\n",
    "We can see a problem with this import. Most entries have a space following the comma, which we don't want. This is easily fixed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movie name', 'gross', 'IMDB rating', 'IMDB votes']\n",
      "['Captain America: Civil War', '1153304495', '7.9', '418614']\n",
      "['Rogue One', '1056057273', '7.9', '334132']\n",
      "['Finding Dory', '1028570889', '7.4', '161213']\n",
      "['Zootopia', '1023784195', '8.1', '302479']\n",
      "['The Jungle Book', '966550600', '7.5', '200798']\n",
      "['The Secret Life Of Pets', '875457937', '6.6', '124027']\n",
      "['Batman v Superman', '873260194', '6.7', '479880']\n",
      "['Deadpool', '783112979', '8.0', '637685']\n",
      "['Suicide Squad', '745600054', '6.2', '404862']\n",
      "['Sing', '632443719', '7.2', '66129']\n"
     ]
    }
   ],
   "source": [
    "with open('topmovies.csv', encoding='UTF-8') as f:\n",
    "    moviescsv = csv.reader(f, delimiter=',', skipinitialspace=True)\n",
    "\n",
    "    for line in moviescsv:\n",
    "        print(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code>csv.reader</code> object provides a large number of options and fixes to get the import just right. Another consideration with csvs is \"what if the entry contains the delimiter?\" For example, what if one of the movie titles in the file I imported contained a comma? For this, we use quotes: punctuation inside quotation marks is ignored. Hence, the <code>csv</code> reader also allows us to specify which character is used for quoting.\n",
    "\n",
    "The <code>csv.reader</code> object has not created a copy of the csv file in Python's memory; it is still reading from the file. Therefore, the file must still be open when we access the lines via the reader. If we want to close the file, we should move the entries into another structure such as a list or dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['movie name', 'gross', 'IMDB rating', 'IMDB votes'], ['Captain America: Civil War', '1153304495', '7.9', '418614'], ['Rogue One', '1056057273', '7.9', '334132'], ['Finding Dory', '1028570889', '7.4', '161213'], ['Zootopia', '1023784195', '8.1', '302479'], ['The Jungle Book', '966550600', '7.5', '200798'], ['The Secret Life Of Pets', '875457937', '6.6', '124027'], ['Batman v Superman', '873260194', '6.7', '479880'], ['Deadpool', '783112979', '8.0', '637685'], ['Suicide Squad', '745600054', '6.2', '404862'], ['Sing', '632443719', '7.2', '66129']]\n"
     ]
    }
   ],
   "source": [
    "with open('topmovies.csv', encoding='UTF-8') as f:\n",
    "    moviescsv = csv.reader(f, delimiter=',', skipinitialspace=True)\n",
    "\n",
    "    movielist = [line for line in moviescsv]\n",
    "\n",
    "print(movielist)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is, of course, a rather crude demonstration (in fact it breaks our rule of avoiding lists of mixed types); we'd likely want to be more organized with how we structure the data we obtain from a csv, but that will depend on your individual needs.\n",
    "\n",
    "Writing to a csv is basically just as easy, and follows practically the same format. Let's put the <code>movielist</code> into a new csv, with different delimiters, and quotation marks around non-numeric data (this will make it easier to import in the future, since with this style, the <code>reader</code> can distinguish between numbers and strings when it reads the file. Firstly, we should actually convert the numeric data into numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['movie name', 'gross', 'IMDB rating', 'IMDB votes'], ['Captain America: Civil War', 1153304495.0, 7.9, 418614.0], ['Rogue One', 1056057273.0, 7.9, 334132.0], ['Finding Dory', 1028570889.0, 7.4, 161213.0], ['Zootopia', 1023784195.0, 8.1, 302479.0], ['The Jungle Book', 966550600.0, 7.5, 200798.0], ['The Secret Life Of Pets', 875457937.0, 6.6, 124027.0], ['Batman v Superman', 873260194.0, 6.7, 479880.0], ['Deadpool', 783112979.0, 8.0, 637685.0], ['Suicide Squad', 745600054.0, 6.2, 404862.0], ['Sing', 632443719.0, 7.2, 66129.0]]\n"
     ]
    }
   ],
   "source": [
    "for row in movielist:\n",
    "    for i, entry in enumerate(row):\n",
    "        try:\n",
    "            row[i] = float(entry)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "print(movielist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly how this code works will be explained in a future article, but try and guess what it does anyway! (Clue: <code>float(\"movie name\")</code> will usually produce an error. What do <code>try</code> and <code>except</code> do?) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our table is in a nicer format, let's write it to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"movies-new.csv\", \"w\", encoding='UTF-8') as f:\n",
    "    # creates a \"writer\" that is ready to write whatever we give to it\n",
    "    moviecsv = csv.writer(f, delimiter='|', quotechar=\"`\", quoting=csv.QUOTE_NONNUMERIC)\n",
    "    \n",
    "    # give the list to the writer\n",
    "    moviecsv.writerows(movielist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting file on my computer looks like this:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "`movie name`|`gross`|`IMDB rating`|`IMDB votes`\n",
    "`Captain America: Civil War`|1153304495.0|7.9|418614.0\n",
    "`Rogue One`|1056057273.0|7.9|334132.0\n",
    "`Finding Dory`|1028570889.0|7.4|161213.0\n",
    "`Zootopia`|1023784195.0|8.1|302479.0\n",
    "`The Jungle Book`|966550600.0|7.5|200798.0\n",
    "`The Secret Life Of Pets`|875457937.0|6.6|124027.0\n",
    "`Batman v Superman`|873260194.0|6.7|479880.0\n",
    "`Deadpool`|783112979.0|8.0|637685.0\n",
    "`Suicide Squad`|745600054.0|6.2|404862.0\n",
    "`Sing`|632443719.0|7.2|66129.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each argument here should be fairly self-explanatory. Rows can be written one at a time with <code>writer.writerow(row)</code>, instead of providing a full list all at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON\n",
    "\n",
    "JSON stands for \"JavaScript Object Notation\". JavaScript is a programming languaged used to make interactive and dynamic webpages. This means there needs to be a way for a JavaScript script in a webpage to send and receive bundles of data without reloading the whole page. The JSON file format is one such solution. However, JSON files can be used to store many kinds of data, and are commonly encountered when grabbing information from the web. In fact, Jupyter notebook files such as this very article are really just JSON files with a different suffix; try opening one in your text editor to see for yourself!\n",
    "\n",
    "Thankfully for us, JSON files are easy for any Python programmer to understand. Here is an example of a JSON file containing an Amazon review for a piece of audio equipment (and yes, Amazon reviews really are sent over to your computer as JSON - in fact most of the things you see on any given Amazon page are):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{\"reviewerID\": \"A2C00NNG1ZQQG2\",\n",
    "\"asin\": \"1384719342\",\n",
    "\"reviewerName\": \"RustyBill \\\"Sunday Rocker\\\"\",\n",
    "\"helpful\": [0, 0],\n",
    "\"reviewText\": \"Nice windscreen protects my MXL mic and prevents pops. Only thing is that the gooseneck is only marginally able to hold the screen in position and requires careful positioning of the clamp to avoid sagging.\",\n",
    "\"overall\": 5.0,\n",
    "\"summary\": \"GOOD WINDSCREEN FOR THE MONEY\",\n",
    "\"unixReviewTime\": 1392336000,\n",
    "\"reviewTime\": \"02 14, 2014\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look familiar? It's basically just a dictionary. This is a good reason for Python programmers to know about JSON files, as it means we can save the data in our Python programs on an external file, so long as the values are of a suitable format (strings, numbers, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, it's not precisely a dictionary. There are some translations that need to be made from the JSON format (and terminology). The dictionary-like structure of a JSON file is called a JSON object. Since objects can have objects as their values, this gives JSON objects a tree-like structure. Booleans in JSON files use all lower case (so Python's <code>True</code> is <code>true</code> in JSON). Lists and tuples are rolled into one object called an array, and all floats and ints are rolled into one object called a number. Let's see how we can import JSONs, using the <code>json</code> module, which does all the necessary translations for us (phew!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main functions of the module are <code>dump</code> and <code>dumps</code> (for creating JSON objects), and <code>load</code> and <code>loads</code> (for reading JSON objects). The <code>s</code> appearing in two of these functions simply stands for string. We'll see the difference in a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reviewerID': 'A2IBPI20UZIR0U', 'asin': '1384719342', 'reviewerName': 'cassandra tu \"Yeah, well, that\\'s just like, u...', 'helpful': [0, 0], 'reviewText': \"Not much to write about here, but it does exactly what it's supposed to. filters out the pop sounds. now my recordings are much more crisp. it is one of the lowest prices pop filters on amazon so might as well buy it, they honestly work the same despite their pricing,\", 'overall': 5.0, 'summary': 'good', 'unixReviewTime': 1393545600, 'reviewTime': '02 28, 2014'}\n",
      "{'reviewerID': 'A14VAT5EAX3D9S', 'asin': '1384719342', 'reviewerName': 'Jake', 'helpful': [13, 14], 'reviewText': \"The product does exactly as it should and is quite affordable.I did not realized it was double screened until it arrived, so it was even better than I had expected.As an added bonus, one of the screens carries a small hint of the smell of an old grape candy I used to buy, so for reminiscent's sake, I cannot stop putting the pop filter next to my nose and smelling it after recording. :DIf you needed a pop filter, this will work just as well as the expensive ones, and it may even come with a pleasing aroma like mine did!Buy this product! :]\", 'overall': 5.0, 'summary': 'Jake', 'unixReviewTime': 1363392000, 'reviewTime': '03 16, 2013'}\n",
      "{'reviewerID': 'A195EZSQDW3E21', 'asin': '1384719342', 'reviewerName': 'Rick Bennette \"Rick Bennette\"', 'helpful': [1, 1], 'reviewText': 'The primary job of this device is to block the breath that would otherwise produce a popping sound, while allowing your voice to pass through with no noticeable reduction of volume or high frequencies. The double cloth filter blocks the pops and lets the voice through with no coloration. The metal clamp mount attaches to the mike stand secure enough to keep it attached. The goose neck needs a little coaxing to stay where you put it.', 'overall': 5.0, 'summary': 'It Does The Job Well', 'unixReviewTime': 1377648000, 'reviewTime': '08 28, 2013'}\n",
      "{'reviewerID': 'A2C00NNG1ZQQG2', 'asin': '1384719342', 'reviewerName': 'RustyBill \"Sunday Rocker\"', 'helpful': [0, 0], 'reviewText': 'Nice windscreen protects my MXL mic and prevents pops. Only thing is that the gooseneck is only marginally able to hold the screen in position and requires careful positioning of the clamp to avoid sagging.', 'overall': 5.0, 'summary': 'GOOD WINDSCREEN FOR THE MONEY', 'unixReviewTime': 1392336000, 'reviewTime': '02 14, 2014'}\n",
      "{'reviewerID': 'A94QU4C90B1AX', 'asin': '1384719342', 'reviewerName': 'SEAN MASLANKA', 'helpful': [0, 0], 'reviewText': \"This pop filter is great. It looks and performs like a studio filter. If you're recording vocals this will eliminate the pops that gets recorded when you sing.\", 'overall': 5.0, 'summary': 'No more pops when I record my vocals.', 'unixReviewTime': 1392940800, 'reviewTime': '02 21, 2014'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"Musical_Instruments_5.json\", \"r\", encoding='UTF-8') as f:\n",
    "    reviews = [json.loads(line) for line in f]\n",
    "\n",
    "for review in reviews[:5]:\n",
    "    print(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break it down. As usual, we open the file using <code>open</code> to give us a file object. This file contains a different JSON object on each line. Because we can read through a file line-by-line, and those lines are read <i>as text</i>, we use <code>loads</code> because each line is a string.\n",
    "\n",
    "One we have loaded it, each JSON object is now precisely a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "This person thought the product they purchased was: good\n"
     ]
    }
   ],
   "source": [
    "print(type(reviews[0]))\n",
    "print(\"This person thought the product they purchased was: {}\".format(reviews[0][\"summary\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This strategy is very good when we have a file containing lots of JSON objects. We read each object (line) as a string and then pass it to <code>loads</code> to convert it. If we have a file containing only a single JSON object, we can pass the whole file to <code>load</code> instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spiritually and mentally inspiring! A book that allows you to question your morals and will help you discover who you really are!\n"
     ]
    }
   ],
   "source": [
    "with open(\"book_review.json\", encoding='UTF-8') as f:\n",
    "    bookreview = json.load(f)\n",
    "\n",
    "print(bookreview[\"reviewText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing JSON objects to files is much the same scenario. This provides a convenient way to save the important information in a Python program, in a way that can be re-opened by the same program, another Python program, or even a program written in a different programming language.\n",
    "\n",
    "Let's encode a JSON object. Suppose I run a business and my program is storing the delivery details of my customers. I might store each customer as a dictionary like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "customer = {\n",
    "    'name': 'Sam Cassidy',\n",
    "    'address': '19 Notareal Avenue, Liverpool',\n",
    "    'postcode': 'L00 9JR',\n",
    "    'purchase-history': [('inflatable pet', 3, '05.09.2016'),\n",
    "                         ('disposable widget', 60, '01.01.2017')],\n",
    "    'Phone number': '0712345567889'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the information contained here is mostly strings, although some are organized into lists of tuples, and there's also a couple of integers here as well. Let's create a JSON object from this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "customer_JSON = json.dumps(customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"Sam Cassidy\", \"address\": \"19 Notareal Avenue, Liverpool\", \"postcode\": \"L00 9JR\", \"purchase-history\": [[\"inflatable pet\", 3, \"05.09.2016\"], [\"disposable widget\", 60, \"01.01.2017\"]]}\n"
     ]
    }
   ],
   "source": [
    "print(customer_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the reproduction is mostly faithful, but our tuples have been turned into JSON arrays. That's okay: if we wish to recover the original tuples when we load from this JSON file, we can just write a function to convert them back.\n",
    "\n",
    "JSON files ignore whitespace, so we can actually make a slightly nicer JSON file by setting the indent parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Sam Cassidy\",\n",
      "  \"address\": \"19 Notareal Avenue, Liverpool\",\n",
      "  \"postcode\": \"L00 9JR\",\n",
      "  \"purchase-history\": [\n",
      "    [\n",
      "      \"inflatable pet\",\n",
      "      3,\n",
      "      \"05.09.2016\"\n",
      "    ],\n",
      "    [\n",
      "      \"disposable widget\",\n",
      "      60,\n",
      "      \"01.01.2017\"\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "customer_JSON = json.dumps(customer, indent=2)\n",
    "print(customer_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is easier to read, and closer to how we defined <code>customer</code> in the file. Since this is now just a string, we can write it to a .json file using the usual write methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('my_customers.json', 'a', encoding='UTF-8') as f:\n",
    "    f.write(customer_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there, the data is saved and can be reopened using <code>json.load()</code> or <code>json.loads()</code>.\n",
    "\n",
    "The difficulty with JSON files is that ultimately, they're only text files. For one, this means encoding is sometimes important, and all the previous things we've said about encoding should be considered. For two, this means that more complicated Python data structures (for example custom made classes, which we'll meet soon enough) might need to be cleverly converted into text, somehow or other. For instance, it might be more useful to inside my program to work with Python's smart \"date\" objects, rather than just strings containing the date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "customer = {\n",
    "    'name': 'Sam Cassidy',\n",
    "    'address': '19 Notareal Avenue, Liverpool',\n",
    "    'postcode': 'L00 9JR',\n",
    "    'purchase-history': [('inflatable pet', 3, date(2016, 9, 5)),\n",
    "                         ('disposable widget', 60, date(2017, 1, 1))],\n",
    "    'Phone number': '0712345567889'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The date object is much smarter than a string. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-09-05\n",
      "1\n",
      "Monday 05 September\n"
     ]
    }
   ],
   "source": [
    "inflatable_pet_date = customer['purchase-history'][0][2]\n",
    "print(inflatable_pet_date)\n",
    "print(inflatable_pet_date.isoweekday()) # day of the week as a number-- this day was a Monday (1st day)!\n",
    "print(inflatable_pet_date.strftime('%A %d %B')) # there's a little mini language to control\n",
    "                                                # this representatio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write this object to a JSON again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type 'date' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1767e5e3802e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcustomer_JSON\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    435\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[0;32m--> 180\u001b[0;31m                         o.__class__.__name__)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type 'date' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "customer_JSON = json.dumps(customer, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Umm... ouch. A simple solution is to write functions that can convert to and from strings and <code>date</code> objects, and just apply them before and after encoding or decoding. The date module of course already provides a way to convert the date to a string -- you can just use <code>str()</code> on the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customer_to_jsonable(customer):\n",
    "    from copy import copy\n",
    "    # so we don't damage the original dictionary\n",
    "    customer = copy(customer)\n",
    "    for i, entry in enumerate(customer['purchase-history']):\n",
    "        customer['purchase-history'][i] = (entry[0], entry[1], str(entry[2]))\n",
    "    return customer\n",
    "\n",
    "def json_to_customer(jsonCust):\n",
    "    for i, entry in enumerate(jsonCust['purchase-history']):\n",
    "        date_list = entry[2].split('-')\n",
    "        date_list = [int(x) for x in date_list]\n",
    "        jsonCust['purchase-history'][i] = (entry[0], entry[1], date(date_list[0], date_list[1], date_list[2]))\n",
    "    return jsonCust\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now call the function before converting to JSON\n",
    "customer_JSON = json.dumps(customer_to_jsonable(customer), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Sam Cassidy\",\n",
      "  \"address\": \"19 Notareal Avenue, Liverpool\",\n",
      "  \"postcode\": \"L00 9JR\",\n",
      "  \"purchase-history\": [\n",
      "    [\n",
      "      \"inflatable pet\",\n",
      "      3,\n",
      "      \"2016-09-05\"\n",
      "    ],\n",
      "    [\n",
      "      \"disposable widget\",\n",
      "      60,\n",
      "      \"2017-01-01\"\n",
      "    ]\n",
      "  ],\n",
      "  \"Phone number\": \"0712345567889\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(customer_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Sam Cassidy', 'address': '19 Notareal Avenue, Liverpool', 'postcode': 'L00 9JR', 'purchase-history': [('inflatable pet', 3, datetime.date(2016, 9, 5)), ('disposable widget', 60, datetime.date(2017, 1, 1))], 'Phone number': '0712345567889'} \n",
      "\n",
      "Customer Sam Cassidy purchased inflatable pet on:\n",
      "2016-09-05\n"
     ]
    }
   ],
   "source": [
    "original_customer = json_to_customer(json.loads(customer_JSON))\n",
    "print(original_customer, '\\n')\n",
    "print(\"Customer {} purchased {} on:\".format(original_customer['name'],\n",
    "                                            original_customer['purchase-history'][0][0]))\n",
    "print(original_customer['purchase-history'][0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, with a little bit of thinking and tinkering, we've recovered all of the original information, even though JSON only allows us to store text.\n",
    "\n",
    "## XML\n",
    "\n",
    "There's another very common way to store and manipulate data on the web. It's called XML, and is in many ways like JSON, but more flexible, and more complicated. Python has an <code>xml</code> module for working with these formats, which again converts hierarchies of attributes into dictionary. There's a great article about how the format works and how to use <code>xml</code> here: http://www.diveintopython3.net/xml.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
